{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative methods for solving linear systems\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the prototypal PDE problem introduced in the Lecture 08:\n",
    "$$\n",
    "-u_{xx}(x) = f(x)\\quad\\mathrm{ in }\\ \\Omega = (0, 1)\n",
    "$$\n",
    "$$\n",
    "u(x) = 0, \\quad\\mathrm{ on }\\ \\partial\\Omega = \\{0, 1\\}\n",
    "$$\n",
    "\n",
    "For the numerical discretization of the problem, we consider a **Finite Difference (FD) Approximation**. Let $n$ be an integer, a consider a uniform subdivision of the interval $(0,1)$ using $n$ equispaced points, denoted by $\\{x_i\\}_{i=0}^n$ . Moreover, let $u_i$ be the FD approximation of $u(x_i)$, and similarly $f_i \\approx f(x_i)$.\n",
    "\n",
    "The linear system that we need to solve is\n",
    "$$\n",
    "u_i = 0 \\qquad\\qquad\\qquad\\qquad i=0,\n",
    "$$\n",
    "$$\n",
    "\\frac{-u_{i-1} + 2u_i - u_{i+1}}{h^2} = f_i \\qquad\\qquad\\qquad i=1, \\ldots, n-1,\\qquad\\qquad\\qquad(P)\n",
    "$$\n",
    "$$\n",
    "u_i = 0 \\qquad\\qquad\\qquad\\qquad i=n.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from numpy import *\n",
    "from matplotlib.pyplot import *\n",
    "\n",
    "n = 33\n",
    "h = 1./(n-1)\n",
    "\n",
    "x=linspace(0,1,n)\n",
    "\n",
    "a = -ones((n-1,)) # Offdiagonal entries\n",
    "b = 2*ones((n,)) # Diagonal entries\n",
    "A = (diag(a, -1) + diag(b, 0) + diag(a, +1))\n",
    "A /= h**2\n",
    "f = x*(1.-x)\n",
    "\n",
    "# Change first row of the matrix A\n",
    "A[0,:] = 0\n",
    "A[:,0] = 0\n",
    "A[0,0] = 1\n",
    "f[0] = 0\n",
    "\n",
    "# Change last row of the matrix A\n",
    "A[-1,:] = 0\n",
    "A[:,-1] = 0\n",
    "A[-1,-1] = 1\n",
    "f[-1] = 0\n",
    "\n",
    "# Solution by direct method\n",
    "u = linalg.solve(A, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jacobi\n",
    "\n",
    "$$ \n",
    "x_i^{k+1} = \\frac{1}{A_{ii}} \\times \\left(b_i - \\sum_{j\\neq i} a_{ij}x_j^k\\right)\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[0, 4]\n"
     ]
    }
   ],
   "source": [
    "aa=[0,1,2,3,4,5,6,7,8,9]\n",
    "print(aa)\n",
    "bb=aa[0:8:4]\n",
    "print(bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2912\n",
      "7.862795872145407e-07\n"
     ]
    }
   ],
   "source": [
    "def jacobi(A, b, nmax=10000, eps=1e-10):\n",
    "    \n",
    "    L = len(b)\n",
    "    \n",
    "    x = np.zeros(L,dtype=float)\n",
    "    x_old = np.zeros(L,dtype=float)\n",
    "    k=1\n",
    "    \n",
    "    while (k<nmax):\n",
    "        \n",
    "        \n",
    "        for i in range(L):\n",
    "            x[i]=(b[i] - dot(A[i,0:i],x_old[0:i]) - dot(A[i,i+1:L],x_old[i+1:L]))/A[i,i]\n",
    "    \n",
    "\n",
    "        if (max(abs(x - x_old))<eps):\n",
    "            break\n",
    "        \n",
    "        x_old[:]= x[:]\n",
    "        k=k+1\n",
    "    \n",
    "    print(k)\n",
    "    return x\n",
    "    \n",
    "\n",
    "sol_jacobi = jacobi(A, f)\n",
    "print(linalg.norm(sol_jacobi - u)/linalg.norm(u))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gauss-Seidel\n",
    "\n",
    "$$ \n",
    "x_i^{k+1} = \\frac{1}{A_{ii}} \\times \\left(b_i - \\sum_{j=0}^{i-1} a_{ij}x_j^{k+1} - \\sum_{j=i+1}^{N} a_{ij}x_j^k\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1528\n",
      "3.9379697006483356e-07\n"
     ]
    }
   ],
   "source": [
    "def gauss_seidel(A,b,nmax=10000, eps=1e-10):\n",
    "    L = len(b)\n",
    "    \n",
    "    x = np.zeros(L,dtype=float)\n",
    "    x_old = np.zeros(L,dtype=float)\n",
    "    k=1\n",
    "    print(k)\n",
    "    while (k<nmax):\n",
    "        \n",
    "        for i in range(L):\n",
    "            x[i]=(b[i] - dot(A[i,0:i],x[0:i]) - dot(A[i,i+1:L],x_old[i+1:L]))/A[i,i]\n",
    "\n",
    "        if (max(abs(x - x_old))<eps):\n",
    "            break\n",
    "        \n",
    "        x_old[:]= x[:]\n",
    "        k=k+1\n",
    "    \n",
    "    print(k)\n",
    "    return x\n",
    "\n",
    "sol_gauss_seidel = gauss_seidel(A, f)\n",
    "print(linalg.norm(sol_gauss_seidel - u)/linalg.norm(u))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "   ## Gradient method\n",
    "   $$\n",
    "   {\\bf r}^k = {\\bf b} - A {\\bf x}^k\n",
    "   $$\n",
    "   \n",
    "   $$\n",
    "   \\alpha^k = \\frac{{\\bf r}^{k^{T}} {\\bf r}^k}{{\\bf r}^{k^{T}} A{\\bf r}^k}\n",
    "   $$\n",
    "   \n",
    "   $$\n",
    "   {\\bf x}^{k+1} = {\\bf x}^k + \\alpha^k {\\bf r}^k\n",
    "   $$\n",
    "   \n",
    "   ### Preconditioned gradient method\n",
    "   $$\n",
    "   P{\\bf z}^k =  {\\bf r}^k\n",
    "   $$\n",
    "   \n",
    "   $$\n",
    "   \\alpha^k = \\frac{{\\bf z}^{k^{T}} {\\bf r}^k}{{\\bf z}^{k^{T}} A{\\bf z}^k}\n",
    "   $$\n",
    " \n",
    "   $$\n",
    "   {\\bf x}^{k+1} = {\\bf x}^k + \\alpha^k {\\bf z}^k\n",
    "   $$ \n",
    "   \n",
    "   $$\n",
    "   {\\bf r}^{k+1} = {\\bf r}^k  - \\alpha^k A{\\bf z}^k\n",
    "   $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2127\n",
      "4.1012770402190106e-07\n",
      "2\n",
      "7.10371752342216e-15\n"
     ]
    }
   ],
   "source": [
    "def gradient(A, b, P, nmax=8000, eps=1e-10):\n",
    "    L = len(b)\n",
    "    \n",
    "    x = np.zeros(L,dtype=float)\n",
    "    x_old = np.zeros(L,dtype=float)\n",
    "    r = np.ones(L,dtype=float)\n",
    "    aa = np.zeros(L,dtype=float)\n",
    "    k=1\n",
    "    #while (k<nmax):\n",
    "    #    r[:] = b[:] - dot(A,x_old)\n",
    "    #    \n",
    "    #    aa=dot(r,r)/dot(r,dot(A,r))\n",
    "    #    \n",
    "    #    x[:] = x_old[:] + aa*r[:]\n",
    "    #    \n",
    "    #        \n",
    "    #    if (max(abs(x - x_old))<eps):\n",
    "    #        break\n",
    "    #    \n",
    "    #    x_old[:]= x[:]\n",
    "    #    k=k+1\n",
    "    \n",
    "    r[:] = b[:] - dot(A,x_old)\n",
    "    while (k<nmax):\n",
    "        #r[:] = b[:] - dot(A,x_old)\n",
    "        \n",
    "        z = np.linalg.solve(P, r)\n",
    "        \n",
    "        aa=dot(z,r)/dot(z,dot(A,z))\n",
    "        \n",
    "        x[:] = x_old[:] + aa*z[:]\n",
    "        \n",
    "        r[:] = r[:] -  aa*dot(A,z)\n",
    "        \n",
    "            \n",
    "        if (max(abs(x - x_old))<eps):\n",
    "            break\n",
    "        \n",
    "        x_old[:]= x[:]\n",
    "        k=k+1\n",
    "    \n",
    "    print(k)\n",
    "    return x\n",
    "    \n",
    "    \n",
    "sol_gradient = gradient(A, f, identity(len(A)))\n",
    "print(linalg.norm(sol_gradient - u)/linalg.norm(u))\n",
    "sol_preconditioned_gradient = gradient(A, f, A)\n",
    "print(linalg.norm(sol_preconditioned_gradient - u)/linalg.norm(u))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjugate gradient\n",
    "   \n",
    "   $$\n",
    "   \\alpha^k = \\frac{{\\bf p}^{k^{T}} {\\bf r}^k}{{\\bf p}^{k^{T}} A{\\bf p}^k}\n",
    "   $$\n",
    "   \n",
    "      \n",
    "   $$\n",
    "   {\\bf x}^{k+1} = {\\bf x}^k + \\alpha^k {\\bf p}^k\n",
    "   $$\n",
    "   \n",
    "   $$\n",
    "   {\\bf r}^{k+1} = {\\bf r}^k - \\alpha^kA {\\bf p}^k\n",
    "   $$\n",
    "\n",
    "   $$\n",
    "   \\beta^k = \\frac{(A{\\bf p}^{k})^{T}{\\bf r}^{k+1}}{(A{\\bf p}^{k})^{T}  {\\bf p}^k}\n",
    "   $$\n",
    "   \n",
    "   $$\n",
    "   {\\bf p}^{k+1} = {\\bf r}^{k+1} - \\beta^k{\\bf p}^k\n",
    "   $$\n",
    "\n",
    "   \n",
    "   ### Preconditioned conjugate gradient\n",
    "   \n",
    "   \n",
    "   $$\n",
    "   \\alpha^k = \\frac{{\\bf p}^{k^{T}} {\\bf r}^k}{(A{\\bf p}^{k})^{T}{\\bf p}^k}\n",
    "   $$\n",
    "   \n",
    "      \n",
    "   $$\n",
    "   {\\bf x}^{k+1} = {\\bf x}^k + \\alpha^k {\\bf p}^k\n",
    "   $$\n",
    "   \n",
    "   $$\n",
    "   {\\bf r}^{k+1} = {\\bf r}^k - \\alpha^kA {\\bf p}^k\n",
    "   $$\n",
    "\n",
    "$$\n",
    "P{\\bf z}^{k+1} = {\\bf r}^{k+1}\n",
    "$$\n",
    "\n",
    "   $$\n",
    "   \\beta^k = \\frac{(A{\\bf p}^{k})^{T}{\\bf z}^{k+1}}{{\\bf p}^{k^T}A  {\\bf p}^k}\n",
    "   $$\n",
    "   \n",
    "   $$\n",
    "   {\\bf p}^{k+1} = {\\bf z}^{k+1} - \\beta^k{\\bf p}^k\n",
    "   $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 2.70422126826e-17\n",
      "2.90303183784e-15\n"
     ]
    }
   ],
   "source": [
    "def conjugate_gradient(A, b, P, nmax=len(A), eps=1e-10):\n",
    "    pass # TODO\n",
    "\n",
    "sol_conjugate_gradient = conjugate_gradient(A, f, identity(len(A)))\n",
    "print(linalg.norm(sol_conjugate_gradient - u)/linalg.norm(u))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
